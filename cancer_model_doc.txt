# Machine Learning Practice Repository

A comprehensive learning repository documenting daily machine learning practice with real-world datasets and models. This project focuses on understanding core ML concepts through hands-on implementation.

## ğŸ“š Overview

This repository contains practical implementations of machine learning algorithms and best practices, including:
- Proper train-test split methodology
- Model evaluation metrics (RÂ², RMSE, MAE)
- Hyperparameter tuning with GridSearchCV
- Pipeline creation for preprocessing and modeling
- Model comparison and visualization

## ğŸ“ Project Structure

```
ml/
â”œâ”€â”€ cancer.ipynb              # Main ML project: Breast Cancer Regression
â”œâ”€â”€ line_regreesion.ipynb     # Linear Regression fundamentals
â”œâ”€â”€ api_explorer.py           # API exploration utilities
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ LICENSE                   # Project license
```

## ğŸ¯ Learning Goals

This project demonstrates:
1. **Proper Data Handling**: Train-test split to avoid data leakage
2. **Model Training**: Linear Regression and K-Nearest Neighbors (KNN)
3. **Hyperparameter Tuning**: Using GridSearchCV with cross-validation
4. **Pipeline Architecture**: Combining preprocessing and modeling
5. **Model Evaluation**: Comparing models on unseen test data
6. **Visualization**: Actual vs Predicted plots for model analysis
7. **Best Practices**: Correct vs Incorrect approaches side-by-side

## ğŸš€ Getting Started

### Prerequisites
```bash
Python 3.8+
pip install scikit-learn
pip install matplotlib
pip install numpy
pip install jupyter
```

### Installation
```bash
# Clone the repository
git clone https://github.com/Hasnatkhan010/ml-learning.git
cd ml

# Install dependencies
pip install -r requirements.txt
```

### Running the Code
```bash
# Launch Jupyter Notebook
jupyter notebook cancer.ipynb

# Or use VS Code with Jupyter extension
```

## ğŸ“Š Project Details: Breast Cancer Regression (cancer.ipynb)

### Dataset
- **Source**: scikit-learn breast cancer dataset
- **Samples**: 569
- **Features**: 30 medical measurements

### Workflow

#### Step 1: Data Loading & Splitting
```python
# Load dataset and split 80/20
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)
```

#### Step 2: Wrong Approach (Educational)
Shows what happens when you train and test on the same data:
- âœ— Trains on entire dataset (569 samples)
- âœ— Tests on entire dataset (569 samples)
- âœ— Artificially high metrics (overfitting)

**Result**: RÂ² Score: ~0.99 (unrealistic!)

#### Step 3: Correct Approach
Proper train-test methodology:
- âœ“ Train model on 80% of data
- âœ“ Evaluate on unseen 20% of data
- âœ“ Realistic performance metrics

**Result**: More honest model assessment

#### Step 4: Pipeline Creation
```python
pipe = Pipeline([
    ("scale", StandardScaler()),      # Normalize features
    ("model", KNeighborsRegressor())  # KNN model
])
```

#### Step 5: Hyperparameter Tuning
Uses GridSearchCV with 3-fold cross-validation:
```python
GridSearchCV(
    estimator=pipe,
    param_grid={'model__n_neighbors': [1,2,3,4,5,6,7,8,9]},
    cv=3
)
```
- Tests different k values (1 to 9)
- Cross-validation prevents overfitting
- Finds optimal n_neighbors on training data

#### Step 6: Model Comparison
Compares two algorithms:
- **Linear Regression**: Assumes linear relationship
- **KNN (GridSearchCV)**: Non-parametric, flexible

#### Step 7: Visualization
4-panel plot showing:
1. Linear Regression - Training Performance
2. Linear Regression - Testing Performance
3. KNN - Training Performance
4. KNN - Testing Performance

## ğŸ“ˆ Key Metrics Explained

| Metric | Formula | Interpretation |
|--------|---------|-----------------|
| **RÂ² Score** | 1 - (SS_res / SS_tot) | How well model explains variance (0-1, higher is better) |
| **RMSE** | âˆš(MSE) | Root Mean Squared Error (same units as target) |
| **MAE** | Mean(\|actual - predicted\|) | Average absolute error (interpretable) |

### Good Model Signs:
- âœ“ Training RÂ² â‰ˆ Testing RÂ² (no overfitting)
- âœ“ Testing metrics lower than training (normal)
- âœ“ Predictions close to diagonal line (Actual vs Predicted plot)

### Bad Model Signs:
- âœ— Training RÂ² >> Testing RÂ² (severe overfitting)
- âœ— Negative RÂ² on test data (very poor)
- âœ— Large scatter around diagonal line

## ğŸ” Important Concepts

### Train-Test Split
Prevents the model from memorizing training data:
```python
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
```
- **Why**: Models perform better on data they've seen
- **Solution**: Test on unseen data
- **Trade-off**: Less training data but honest evaluation

### GridSearchCV
Automated hyperparameter tuning with cross-validation:
- Tries multiple hyperparameter combinations
- Uses cross-validation (divides training data further)
- Returns best parameters found on training data
- Prevents tuning overfitting

### Pipeline
Combines preprocessing and modeling:
```python
Pipeline([
    ("scale", StandardScaler()),      # Preprocessing step
    ("model", KNeighborsRegressor())  # Modeling step
])
```
- Ensures preprocessing applied consistently
- Prevents data leakage during cross-validation

## ğŸ“š Learning Resources

- [Scikit-learn Documentation](https://scikit-learn.org)
- [ML Best Practices](https://machinelearningmastery.com)
- [Cross-Validation Guide](https://scikit-learn.org/stable/modules/cross_validation.html)
- [Hyperparameter Tuning](https://scikit-learn.org/stable/modules/grid_search.html)

## ğŸ“ What You'll Learn

By studying this repository, you'll understand:
- âœ“ Why train-test split is critical
- âœ“ How to properly evaluate models
- âœ“ Difference between overfitting and generalization
- âœ“ Building ML pipelines
- âœ“ Hyperparameter tuning techniques
- âœ“ Comparing different models
- âœ“ Visualizing model performance

## ğŸ“ Daily Learning Log

Track your learning progress:
- **Day 1**: Understood train-test split importance
- **Day 2**: Implemented Linear Regression correctly
- **Day 3**: Learned about GridSearchCV and cross-validation
- **Day 4**: Built pipelines and compared models
- **Day 5**: Mastered visualization techniques

## ğŸ¤ Contributing

This is a personal learning repository. Feel free to:
- Fork it for your own learning
- Add comments and explanations
- Implement additional models
- Test on other datasets

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## â­ Tips for Using This Repository

1. **Run sequentially**: Execute cells in order (1 to 10)
2. **Pause and understand**: Read comments and explanations
3. **Modify and experiment**: Change hyperparameters and see results
4. **Compare approaches**: Notice difference between Step 2 (wrong) and Step 3 (correct)
5. **Study visualizations**: The 4-panel plot reveals model behavior


